{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1070,
   "id": "4ffe2903",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1071,
   "id": "14b1beec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function implements the OLS estimator which takes in 1D features, x, expected values y as inputs, and returns two parameters\n",
    "def ols_estimator_1d(x, y):\n",
    "    \n",
    "    m = x.shape[0] # Number of training examples\n",
    "    \n",
    "    # Dependent variable (1D) - X matrix\n",
    "    X = np.array([np.ones(m), x]) \n",
    "    X = X.T # Transpose matrix to hold a shape of m x 2 to facilitate matrix multiplication of its transpose with vector y of shape m x 1 \n",
    "\n",
    "\n",
    "    # Independent variable - y vector\n",
    "    Y = y[..., None]\n",
    "\n",
    "    # Implementing OLS Estimator\n",
    "    # 1D OLS parameters - [\\beta_{0}, \\beta_{1}], y-intercept and gradient respectively\n",
    "    betas = np.linalg.inv(X.T @ X) @ X.T @ Y \n",
    "\n",
    "    betas = betas.flatten()\n",
    "    \n",
    "    return betas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e64f1f",
   "metadata": {},
   "source": [
    "# Q2: Create your synthetic datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1072,
   "id": "a1add07a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of datasets: 100\n"
     ]
    }
   ],
   "source": [
    "random.seed(10)\n",
    "np.random.seed(10)\n",
    "\n",
    "\n",
    "a = 2\n",
    "b = -3\n",
    "\n",
    "# Creates 10 datasets, with 100 data points each\n",
    "m = 100 # Number of datasets\n",
    "n = 10 # training examples \n",
    "\n",
    "mean = 0\n",
    "var = 1\n",
    "\n",
    "def generate_one_dataset(n, mean, var):\n",
    "    # Create x and y data\n",
    "    x = np.array([random.uniform(-1, 1) for i in range(n)])\n",
    "    error = np.random.normal(loc=mean, scale= math.sqrt(var), size=(n,))\n",
    "    y = np.array(list(map(lambda x_1, e: a*x_1 + b + e, x, error)))\n",
    "    return [x, y]\n",
    "\n",
    "def generate_m_datasets(m, n, mean, var):\n",
    "    return [generate_one_dataset(n, mean, var) for i in range(m)]\n",
    "\n",
    "datasets1 = generate_m_datasets(m, n, mean, var) \n",
    "\n",
    "print(f'Number of datasets: {len(datasets1)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b70dc4",
   "metadata": {},
   "source": [
    "# Q3: Run OLS on these 100 datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1073,
   "id": "1d6c8c5c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run OLS Estimator on all 100 datasets\n",
    "\n",
    "x = np.linspace(-60, 60, 5)\n",
    "\n",
    "# This function plots all the regression functions for each dataset as a line plot\n",
    "def plot_all_regressions(datasets, title, ax):\n",
    "    lines = [] \n",
    "    all_betas = [] \n",
    "\n",
    "    # First plot: Show 100 lines for each parameter generated\n",
    "    for d in datasets:\n",
    "        betas = ols_estimator_1d(d[0], d[1])\n",
    "        all_betas.append(betas)\n",
    "        # Plot each linear regression function \n",
    "        lines += ax.plot(x, np.array(list(map(lambda x: betas[0] + betas[1]*x, x))), c='red') \n",
    "\n",
    "    # Plot the original plot with its coefficients    \n",
    "    lines += ax.plot(x, np.array(list(map(lambda x: b + a*x, x))), c='black', label= \"ground truth\")\n",
    "\n",
    "    ax.legend(lines[-2:], ['random datasets','ground truth'])\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel('x')\n",
    "    ax.set_ylabel('y')\n",
    "    ax.set_ylim((-60, 60))\n",
    "    ax.set_aspect('equal', 'box')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plt.draw()\n",
    "    return all_betas\n",
    "\n",
    "    \n",
    "# This function plots all the predicted parameters for each dataset as a scatter plot\n",
    "def plot_all_parameters(datasets, title, ax):\n",
    "    # Second plot to show each 100 parameter pair \n",
    "    all_betas = [] \n",
    "\n",
    "    # First plot: Show 100 lines for each parameter generated\n",
    "    for d in datasets:\n",
    "        betas = ols_estimator_1d(d[0], d[1])\n",
    "        all_betas.append(betas)\n",
    "    \n",
    "    temp_betas = np.array(all_betas)\n",
    "    temp_betas_t = temp_betas.T\n",
    "\n",
    "    ax.set(xlim= (-60, 60), ylim=(-60, 60))\n",
    "    ax.set_aspect('equal', 'box')\n",
    "    ax.scatter(temp_betas_t[0], temp_betas_t[1], c='red', label='random datasets')\n",
    "    \n",
    "    # Plot the original parameters\n",
    "    ax.scatter([b],[a], c='black', label='ground truth')\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel('$\\hat{b}$')\n",
    "    ax.set_ylabel('$\\hat{a}$')\n",
    "    ax.legend()\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.draw()\n",
    "    \n",
    "# This function generates consecutive plots with comparable scales and axis value \n",
    "def show_and_compare_regressions(list_of_datasets, R, titles, figsize):\n",
    "    fig, axs = plt.subplots(nrows=R , ncols=1, figsize= figsize)\n",
    "    i = 0\n",
    "    for ax in axs:\n",
    "        plot_all_regressions(list_of_datasets[i], titles[i], ax)\n",
    "        i+=1\n",
    "\n",
    "# This function generates consecutive plots with comparable scales and axis value \n",
    "def show_and_compare_parameters(list_of_datasets, R, titles, figsize):\n",
    "    fig, axs = plt.subplots(nrows=R , ncols=1, figsize= figsize)\n",
    "    i = 0\n",
    "    for ax in axs:\n",
    "        plot_all_parameters(list_of_datasets[i], titles[i], ax)\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c99796",
   "metadata": {},
   "source": [
    "# Q4:  Change the dataset size n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1074,
   "id": "07c1e57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100\n",
    "datasets2 = generate_m_datasets(m, n, mean, var) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1075,
   "id": "67c272ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 2 \n",
    "datasets3 = generate_m_datasets(m, n, mean, var) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ce4cbe",
   "metadata": {},
   "source": [
    "# Plot plots from Q3 to Q4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a9f716",
   "metadata": {},
   "source": [
    "## Regressions computed from 3 sets of 100 random datasets, each with different training size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541b7770",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_and_compare_regressions([datasets1, datasets2, datasets3], 3, ['Q3 (100 datasets, 10 data points each)', 'Q4(100 datasets, 100 data points each)', 'Q4(100 datasets, 2 data points each)'], (12, 12))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa060de",
   "metadata": {},
   "source": [
    "## Predicted parameters computed from 3 sets of 100 random datasets, each with different training size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44052168",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_and_compare_parameters([datasets1, datasets2, datasets3], 3, ['Q3 (100 datasets, 10 data points each): $\\hat{y} = \\hat{a}x + \\hat{b}$', 'Q4(100 datasets, 100 data points each): $\\hat{y} = \\hat{a}x + \\hat{b}$', 'Q4(100 datasets, 2 data points each): $\\hat{y} = \\hat{a}x + \\hat{b}$'], (12, 12))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce7c3550",
   "metadata": {},
   "source": [
    "# Q5: Change the noise level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd8a3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db0fa53",
   "metadata": {},
   "source": [
    "## Regressions computed with different variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4cb74fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "var = 0.01\n",
    "datasets4 = generate_m_datasets(m, n, mean, var) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46df1dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_and_compare_regressions([datasets4, datasets5], 2, ['Q5 (100 datasets, 10 data points each, $\\sigma^{2} = 0.01$)', 'Q4(100 datasets, 100 data points each, $\\sigma^{2} = 100$)'], (12, 12))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "939096d2",
   "metadata": {},
   "source": [
    "# Parameters with different variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af99523f",
   "metadata": {},
   "outputs": [],
   "source": [
    "var = 100 \n",
    "datasets5 = generate_m_datasets(m, n, mean, var) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7960e60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_and_compare_parameters([datasets4, datasets5], 2, ['Q5 (100 datasets, 10 data points each, $\\sigma^{2} = 0.01$)', 'Q4(100 datasets, 100 data points each, $\\sigma^{2} = 100$)'], (12, 12))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LinearRegressionPlayground",
   "language": "python",
   "name": "linearregressionplayground"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
